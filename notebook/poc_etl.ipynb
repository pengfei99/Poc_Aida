{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ba3cd4-95ac-433f-80e3-18b6966bada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f469701-1df3-4e06-8364-549002c22318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-e0a85f61-9893-4915-a676-f8936f75b18d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.2.24 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      "downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.24/postgresql-42.2.24.jar ...\n",
      "\t[SUCCESSFUL ] org.postgresql#postgresql;42.2.24!postgresql.jar (126ms)\n",
      "downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.5.0/checker-qual-3.5.0.jar ...\n",
      "\t[SUCCESSFUL ] org.checkerframework#checker-qual;3.5.0!checker-qual.jar (34ms)\n",
      ":: resolution report :: resolve 839ms :: artifacts dl 166ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.2.24 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   2   |   2   |   0   ||   2   |   2   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-e0a85f61-9893-4915-a676-f8936f75b18d\n",
      "\tconfs: [default]\n",
      "\t2 artifacts copied, 0 already retrieved (1192kB/9ms)\n",
      "2022-04-27 08:36:53,194 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-04-27 08:36:56,155 WARN spark.ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "local=False\n",
    "if local:\n",
    "    spark=SparkSession.builder.master(\"local[4]\") \\\n",
    "                  .appName(\"aida_poc_etl\").getOrCreate()\n",
    "else:\n",
    "    spark=SparkSession.builder \\\n",
    "                      .master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "                      .appName(\"aida_poc_etl\") \\\n",
    "                      .config(\"spark.kubernetes.container.image\",os.environ[\"IMAGE_NAME\"]) \\\n",
    "                      .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\",os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "                      .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "                      .config(\"spark.executor.instances\", \"8\") \\\n",
    "                      .config(\"spark.executor.memory\",\"16g\") \\\n",
    "                      .config('spark.jars.packages','org.postgresql:postgresql:42.2.24') \\\n",
    "                      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb409d53-4dde-4ada-b8f3-562363b6822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:54:07,198 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_29 !\n",
      "2022-04-27 08:54:07,198 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_51 !\n",
      "2022-04-27 08:54:07,198 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_11 !\n",
      "2022-04-27 08:54:07,198 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_59 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_68 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_19 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_34 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_94 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_44 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_103 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_86 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_8 !\n",
      "2022-04-27 08:54:07,199 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_77 !\n",
      "2022-04-27 08:54:08,291 ERROR scheduler.TaskSchedulerImpl: Lost executor 9 on 10.233.115.175: \n",
      "The executor with id 9 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:02Z\n",
      "\t container finished at: 2022-04-27T08:54:07Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:54:08,296 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 13.0 (TID 443) (10.233.115.175 executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: \n",
      "The executor with id 9 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:02Z\n",
      "\t container finished at: 2022-04-27T08:54:07Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "work_dir=\"s3a://projet-poc-aida/rp\"\n",
    "file_name=\"individus.csv\"\n",
    "file_path=f\"{work_dir}/{file_name}\"\n",
    "\n",
    "# use option\n",
    "df=spark.read\\\n",
    "    .option(\"header\",True)\\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"delimiter\",';') \\\n",
    "    .csv(path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bbdb9ee-f8ac-4218-bf99-d9b6b2f078e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:55:56,666 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+-----------------+--------------+-------------------+---------------+------------------+-------------+--------------+------------------+----+----------+-------+----------------+-------+---+---------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "|region_residence|departement_residence|commune_residence|region_travail|departement_travail|commune_travail|commune_anterieure|commune_etude|pays_naissance|poids             |sexe|statut_pro|densite|recherche_emploi|diplome|age|variable00     |variable01|variable02|variable03|variable04|variable05|variable06|variable07|variable08|variable09|variable10|variable11|variable12|variable13|variable14|variable15|variable16|variable17|variable18|variable19|variable20|variable21|variable22|variable23|variable24|variable25|variable26|variable27|variable28|variable29|variable30|variable31|variable32|variable33|variable34|variable35|variable36|variable37|variable38|variable39|variable40|variable41|variable42|variable43|variable44|variable45|variable46|variable47|variable48|variable49|\n",
      "+----------------+---------------------+-----------------+--------------+-------------------+---------------+------------------+-------------+--------------+------------------+----+----------+-------+----------------+-------+---+---------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "|53              |22                   |22170            |53            |22                 |22170          |22170             |22170        |99            |1.197604824388689 |2   |Z         |3      |0               |2      |3  |930660000002340|1         |6         |9316      |652242.5  |6871102.2 |2         |2017      |1         |1989      |5         |9         |28027     |27        |27        |2         |75113     |999       |1         |11        |2         |2         |111       |111       |1         |ZZZ       |997       |0         |997       |1         |2         |2         |Z         |YYYYY     |ZZZZZ     |2         |93055     |99999     |16        |16        |1G        |Z         |1         |0         |930660902 |1         |93066     |999       |999       |6         |\n",
      "|75              |17                   |17082            |27            |71                 |71388          |17082             |17082        |41            |1.2372214738347511|1   |Z         |3      |0               |6      |9  |930660000002340|1         |6         |9316      |652242.5  |6871102.2 |2         |2017      |1         |1989      |5         |9         |28027     |27        |27        |2         |75113     |999       |1         |11        |2         |2         |111       |111       |1         |ZZZ       |997       |0         |997       |1         |2         |2         |Z         |YYYYY     |ZZZZZ     |2         |93055     |99999     |16        |16        |1G        |Z         |1         |0         |930660902 |1         |93066     |999       |999       |6         |\n",
      "|84              |38                   |38002            |84            |38                 |38002          |38002             |38002        |12            |0.5948016605623568|1   |1         |3      |2               |6      |1  |930660000002340|1         |6         |9316      |652242.5  |6871102.2 |2         |2017      |1         |1989      |5         |9         |28027     |27        |27        |2         |75113     |999       |1         |11        |2         |2         |111       |111       |1         |ZZZ       |997       |0         |997       |1         |2         |2         |Z         |YYYYY     |ZZZZZ     |2         |93055     |99999     |16        |16        |1G        |Z         |1         |0         |930660902 |1         |93066     |999       |999       |6         |\n",
      "|75              |17                   |17377            |75            |17                 |17377          |17377             |17377        |51            |1.1798062245499321|1   |2         |4      |1               |1      |3  |930660000002340|1         |6         |9316      |652242.5  |6871102.2 |2         |2017      |1         |1989      |5         |9         |28027     |27        |27        |2         |75113     |999       |1         |11        |2         |2         |111       |111       |1         |ZZZ       |997       |0         |997       |1         |2         |2         |Z         |YYYYY     |ZZZZZ     |2         |93055     |99999     |16        |16        |1G        |Z         |1         |0         |930660902 |1         |93066     |999       |999       |6         |\n",
      "|24              |36                   |36189            |84            |43                 |43125          |36189             |36189        |99            |0.8898426903110267|1   |1         |3      |2               |1      |2  |930660000002340|1         |6         |9316      |652242.5  |6871102.2 |2         |2017      |1         |1989      |5         |9         |28027     |27        |27        |2         |75113     |999       |1         |11        |2         |2         |111       |111       |1         |ZZZ       |997       |0         |997       |1         |2         |2         |Z         |YYYYY     |ZZZZZ     |2         |93055     |99999     |16        |16        |1G        |Z         |1         |0         |930660902 |1         |93066     |999       |999       |6         |\n",
      "+----------------+---------------------+-----------------+--------------+-------------------+---------------+------------------+-------------+--------------+------------------+----+----------+-------+----------------+-------+---+---------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.cache()\n",
    "df.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9d0b9d7-9b48-4eb2-b982-9d082a4396e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84433448-d167-490c-9876-da29b94a2481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- region_residence: integer (nullable = true)\n",
      " |-- departement_residence: string (nullable = true)\n",
      " |-- commune_residence: string (nullable = true)\n",
      " |-- region_travail: integer (nullable = true)\n",
      " |-- departement_travail: string (nullable = true)\n",
      " |-- commune_travail: string (nullable = true)\n",
      " |-- commune_anterieure: string (nullable = true)\n",
      " |-- commune_etude: string (nullable = true)\n",
      " |-- pays_naissance: integer (nullable = true)\n",
      " |-- poids: double (nullable = true)\n",
      " |-- sexe: integer (nullable = true)\n",
      " |-- statut_pro: string (nullable = true)\n",
      " |-- densite: integer (nullable = true)\n",
      " |-- recherche_emploi: integer (nullable = true)\n",
      " |-- diplome: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- variable00: long (nullable = true)\n",
      " |-- variable01: integer (nullable = true)\n",
      " |-- variable02: integer (nullable = true)\n",
      " |-- variable03: integer (nullable = true)\n",
      " |-- variable04: double (nullable = true)\n",
      " |-- variable05: double (nullable = true)\n",
      " |-- variable06: integer (nullable = true)\n",
      " |-- variable07: integer (nullable = true)\n",
      " |-- variable08: integer (nullable = true)\n",
      " |-- variable09: integer (nullable = true)\n",
      " |-- variable10: integer (nullable = true)\n",
      " |-- variable11: integer (nullable = true)\n",
      " |-- variable12: integer (nullable = true)\n",
      " |-- variable13: integer (nullable = true)\n",
      " |-- variable14: integer (nullable = true)\n",
      " |-- variable15: integer (nullable = true)\n",
      " |-- variable16: integer (nullable = true)\n",
      " |-- variable17: integer (nullable = true)\n",
      " |-- variable18: integer (nullable = true)\n",
      " |-- variable19: integer (nullable = true)\n",
      " |-- variable20: integer (nullable = true)\n",
      " |-- variable21: integer (nullable = true)\n",
      " |-- variable22: integer (nullable = true)\n",
      " |-- variable23: integer (nullable = true)\n",
      " |-- variable24: integer (nullable = true)\n",
      " |-- variable25: string (nullable = true)\n",
      " |-- variable26: integer (nullable = true)\n",
      " |-- variable27: integer (nullable = true)\n",
      " |-- variable28: integer (nullable = true)\n",
      " |-- variable29: integer (nullable = true)\n",
      " |-- variable30: integer (nullable = true)\n",
      " |-- variable31: integer (nullable = true)\n",
      " |-- variable32: string (nullable = true)\n",
      " |-- variable33: string (nullable = true)\n",
      " |-- variable34: string (nullable = true)\n",
      " |-- variable35: integer (nullable = true)\n",
      " |-- variable36: integer (nullable = true)\n",
      " |-- variable37: integer (nullable = true)\n",
      " |-- variable38: integer (nullable = true)\n",
      " |-- variable39: integer (nullable = true)\n",
      " |-- variable40: string (nullable = true)\n",
      " |-- variable41: string (nullable = true)\n",
      " |-- variable42: integer (nullable = true)\n",
      " |-- variable43: integer (nullable = true)\n",
      " |-- variable44: integer (nullable = true)\n",
      " |-- variable45: integer (nullable = true)\n",
      " |-- variable46: integer (nullable = true)\n",
      " |-- variable47: integer (nullable = true)\n",
      " |-- variable48: integer (nullable = true)\n",
      " |-- variable49: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2835d4f-f6e3-47cd-8353-3263bae3ba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data partition number: 109\n"
     ]
    }
   ],
   "source": [
    "partition_number=df.rdd.getNumPartitions()\n",
    "print(f\"Data partition number: {partition_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc13abd-cc24-436d-8582-5c2f6f272b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:56:57,817 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_85 !\n",
      "2022-04-27 08:56:57,817 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_107 !\n",
      "2022-04-27 08:56:57,817 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_16 !\n",
      "2022-04-27 08:56:57,817 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_6 !\n",
      "2022-04-27 08:56:57,817 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_62 !\n",
      "2022-04-27 08:56:57,818 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_50 !\n",
      "2022-04-27 08:56:57,818 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_38 !\n",
      "2022-04-27 08:56:57,818 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_24 !\n",
      "2022-04-27 08:56:57,818 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_96 !\n",
      "2022-04-27 08:56:57,818 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_72 !\n",
      "2022-04-27 08:56:59,343 ERROR scheduler.TaskSchedulerImpl: Lost executor 12 on 10.233.118.48: \n",
      "The executor with id 12 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:05Z\n",
      "\t container finished at: 2022-04-27T08:56:57Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:56:59,343 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 18.0 (TID 664) (10.233.118.48 executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: \n",
      "The executor with id 12 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:05Z\n",
      "\t container finished at: 2022-04-27T08:56:57Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:57:05,700 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_70 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_36 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_46 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_105 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_12 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_61 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_7 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_30 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_80 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_20 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_88 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_95 !\n",
      "2022-04-27 08:57:05,701 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_54 !\n",
      "2022-04-27 08:57:07,371 ERROR scheduler.TaskSchedulerImpl: Lost executor 14 on 10.233.115.135: \n",
      "The executor with id 14 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:05Z\n",
      "\t container finished at: 2022-04-27T08:57:05Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:57:07,371 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 18.0 (TID 669) (10.233.115.135 executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: \n",
      "The executor with id 14 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:05Z\n",
      "\t container finished at: 2022-04-27T08:57:05Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:57:08,647 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_49 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_37 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_25 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_63 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_74 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_0 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_17 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_84 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_10 !\n",
      "2022-04-27 08:57:08,648 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_97 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_78 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_35 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_55 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_83 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_5 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_108 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_13 !\n",
      "2022-04-27 08:57:09,236 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_21 !\n",
      "2022-04-27 08:57:09,237 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_100 !\n",
      "2022-04-27 08:57:09,237 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_45 !\n",
      "2022-04-27 08:57:09,237 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_60 !\n",
      "2022-04-27 08:57:09,237 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_69 !\n",
      "2022-04-27 08:57:09,237 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_31 !\n",
      "2022-04-27 08:57:09,237 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_38_93 !\n",
      "2022-04-27 08:57:09,394 ERROR scheduler.TaskSchedulerImpl: Lost executor 6 on 10.233.121.122: \n",
      "The executor with id 6 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:36:58Z\n",
      "\t container finished at: 2022-04-27T08:57:08Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:57:09,399 WARN scheduler.TaskSetManager: Lost task 5.1 in stage 18.0 (TID 679) (10.233.121.122 executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: \n",
      "The executor with id 6 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:36:58Z\n",
      "\t container finished at: 2022-04-27T08:57:08Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:57:10,422 ERROR scheduler.TaskSchedulerImpl: Lost executor 16 on 10.233.112.213: \n",
      "The executor with id 16 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:05Z\n",
      "\t container finished at: 2022-04-27T08:57:09Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "2022-04-27 08:57:10,423 WARN scheduler.TaskSetManager: Lost task 13.0 in stage 18.0 (TID 678) (10.233.112.213 executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: \n",
      "The executor with id 16 exited with exit code 137(SIGKILL, possible container OOM).\n",
      "\n",
      "\n",
      "\n",
      "The API gave the following container statuses:\n",
      "\n",
      "\n",
      "\t container name: spark-kubernetes-executor\n",
      "\t container image: inseefrlab/jupyter-datascience:py3.9.7-spark3.2.0\n",
      "\t container state: terminated\n",
      "\t container started at: 2022-04-27T08:41:05Z\n",
      "\t container finished at: 2022-04-27T08:57:09Z\n",
      "\t exit code: 137\n",
      "\t termination reason: OOMKilled\n",
      "      \n",
      "[Stage 18:=====>                                                 (10 + 8) / 109]\r"
     ]
    }
   ],
   "source": [
    "output_file=\"individus_snappy_parquet\"\n",
    "\n",
    "output_path=f\"{work_dir}/{output_file}\"\n",
    "\n",
    "df.write.mode(\"overwrite\").parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79259771-c758-4d27-ab63-6ae7698b7ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
